{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3810edb8",
   "metadata": {},
   "source": [
    "5min~1hou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import signal\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, TimeoutError\n",
    "from rasengan.problems.facility_location_problem import generate_flp\n",
    "import numpy as np\n",
    "from rasengan.solvers.optimizers import CobylaOptimizer\n",
    "from rasengan.solvers.qiskit import (\n",
    "    RasenganSegmentedSolver, BitFlipNoiseAerProvider, NoisyDdsimProvider\n",
    ")\n",
    "np.random.seed(0x7f)\n",
    "random.seed(0x7f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b56803",
   "metadata": {},
   "outputs": [],
   "source": [
    "depolarizing_csv_path = \"depolarizing.csv\"\n",
    "num_cases = 30\n",
    "flp_problems_pkg, flp_configs_pkg = generate_flp(num_cases, [(1, 2)], 1, 20)\n",
    "problems_pkg = list(\n",
    "    itertools.chain(\n",
    "        enumerate(flp_problems_pkg),\n",
    "    )\n",
    ")\n",
    "\n",
    "evaluation_metrics = ['best_solution_probs', 'in_constraints_probs', 'ARG', 'iteration_count', 'classcial', 'quantum', 'run_times']\n",
    "headers = ['pkid', 'pbid', 'layers', \"variables\", 'constraints', 'method', 'p_gate1'] + evaluation_metrics\n",
    "\n",
    "solvers = [RasenganSegmentedSolver]\n",
    "p_gate1_lst = [1e-4,3e-4,5e-4,1e-3]\n",
    "\n",
    "def process_layer(prb, num_layers, solver,p):\n",
    "    opt = CobylaOptimizer(max_iter=200)\n",
    "    aer = BitFlipNoiseAerProvider(p_meas= 1.525e-2, p_reset=p, p_gate1=p)\n",
    "    prb.set_penalty_lambda(400)\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        provider = aer,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "        num_segments = 100,\n",
    "\n",
    "    )\n",
    "    used_solver.solve()\n",
    "    eval = used_solver.evaluation()\n",
    "    time = list(used_solver.time_analyze())\n",
    "    run_times = used_solver.run_counts()\n",
    "    result = eval + time + [run_times]\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 24 * 3 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    with open(f'{depolarizing_csv_path}', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count()\n",
    "    for pkid, (diff_level, problems) in enumerate(problems_pkg):\n",
    "        for p in tqdm(p_gate1_lst, desc=\"Evaluating p_gate1\"):\n",
    "            num_processes = num_processes_cpu // 4\n",
    "\n",
    "            with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                futures = []\n",
    "                layer = 5\n",
    "                solver = RasenganSegmentedSolver\n",
    "                for pbid, prb in enumerate(problems):\n",
    "                    future = executor.submit(process_layer, prb, layer, solver, p)\n",
    "                    futures.append((future, prb, pkid, pbid, layer, solver.__name__,p))\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "                for future, prb, pkid, pbid, layer, solver, p in tqdm(futures, desc=\"    processing\", leave=False):\n",
    "                    current_time = time.perf_counter()\n",
    "                    remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "                    diff = []\n",
    "                    try:\n",
    "                        metrics = future.result(timeout=remaining_time)\n",
    "                        diff.extend(metrics)\n",
    "                        # print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} p_gate1={p} has executed successfully.\")\n",
    "                    except MemoryError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} p_gate1={p} encountered a MemoryError.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('memory_error')\n",
    "                    except TimeoutError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} p_gate1={p} timed out.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('timeout')\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "                    finally:\n",
    "                        row = [pkid, pbid, layer, len(prb.variables), len(prb.lin_constr_mtx), solver, p] + diff\n",
    "                        with open(f'{depolarizing_csv_path}', mode='a', newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow(row)  # Write row immediately\n",
    "                        num_complete += 1\n",
    "                        if num_complete == len(futures):\n",
    "                            # print(f'problem_pkg_{pkid} has finished')\n",
    "                            for process in executor._processes.values():\n",
    "                                os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {depolarizing_csv_path}')\n",
    "    print(f\"Time elapsed: {time.perf_counter() - all_start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_csv_path = \"amp_damping_probability.csv\"\n",
    "num_cases = 10\n",
    "flp_problems_pkg, flp_configs_pkg = generate_flp(num_cases, [(1, 2)], 1, 10)\n",
    "problems_pkg = list(\n",
    "    itertools.chain(\n",
    "        enumerate(flp_problems_pkg),\n",
    "    )\n",
    ")\n",
    "\n",
    "solvers = [RasenganSegmentedSolver]\n",
    "evaluation_metrics = ['best_solution_probs', 'in_constraints_probs', 'ARG', 'iteration_count', 'classcial', 'quantum', 'run_times']\n",
    "headers = ['pkid', 'pbid', 'layers', \"variables\", 'constraints', 'method', 'amp'] + evaluation_metrics\n",
    "\n",
    "\n",
    "def process_layer(prb, num_layers, solver, amp):\n",
    "    opt = CobylaOptimizer(max_iter=200)\n",
    "    noisy_ddsim = NoisyDdsimProvider(amp_damping_probability=amp)\n",
    "    prb.set_penalty_lambda(400)\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        provider = noisy_ddsim,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "        num_segments=1000,\n",
    "    )\n",
    "    used_solver.solve()\n",
    "    eval = used_solver.evaluation()\n",
    "    time = list(used_solver.time_analyze())\n",
    "    run_times = used_solver.run_counts()\n",
    "    return eval + time + [run_times]\n",
    "\n",
    "\n",
    "amp_damping_probability = [0.0, 0.005, 0.01, 0.015]\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 24 * 10 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    # print(amp_csv_path)\n",
    "    with open(f'{amp_csv_path}', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count()\n",
    "    # pkid-pbid: 问题包序-包内序号\n",
    "    for pkid, (diff_level, problems) in enumerate(problems_pkg):\n",
    "        # if pkid % 5 == 0:\n",
    "        #     continue\n",
    "        for amp in tqdm(amp_damping_probability, desc=\"Evaluating amp_damping_probability\"):\n",
    "            for solver in solvers:\n",
    "                num_processes = num_processes_cpu // 4\n",
    "\n",
    "                with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                    futures = []\n",
    "                    layer = 5\n",
    "                \n",
    "                    for pbid, prb in enumerate(problems):\n",
    "\n",
    "                        # print(f'{pkid}-{pbid}, {layer}, {solver} build')\n",
    "                        future = executor.submit(process_layer, prb, layer, solver, amp)\n",
    "                        futures.append((future, prb, pkid, pbid, layer, solver.__name__, amp))\n",
    "\n",
    "                    start_time = time.perf_counter()\n",
    "                    for future, prb, pkid, pbid, layer, solver, amp in tqdm(futures, desc=\"    processing\", leave=False):\n",
    "                        current_time = time.perf_counter()\n",
    "                        remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "                        diff = []\n",
    "                        try:\n",
    "                            metrics = future.result(timeout=remaining_time)\n",
    "                            diff.extend(metrics)\n",
    "                            # print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} executed successfully.\")\n",
    "                        except MemoryError:\n",
    "                            print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} encountered a MemoryError.\")\n",
    "                            for dict_term in evaluation_metrics:\n",
    "                                diff.append('memory_error')\n",
    "                        except TimeoutError:\n",
    "                            print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} timed out.\")\n",
    "                            for dict_term in evaluation_metrics:\n",
    "                                diff.append('timeout')\n",
    "                        except Exception as e:\n",
    "                            print(f\"An error occurred: {e}\")\n",
    "                        finally:\n",
    "                            row = [pkid, pbid, layer, len(prb.variables), len(prb.lin_constr_mtx), solver, amp] + diff\n",
    "                            with open(f'{amp_csv_path}', mode='a', newline='') as file:\n",
    "                                writer = csv.writer(file)\n",
    "                                writer.writerow(row)  # Write row immediately\n",
    "                            num_complete += 1\n",
    "                            if num_complete == len(futures):\n",
    "                                # print(f'problem_pkg_{pkid} has finished')\n",
    "                                for process in executor._processes.values():\n",
    "                                    os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {amp_csv_path}')\n",
    "    print(f\"Time elapsed: {time.perf_counter() - all_start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df581af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # 显示所有行\n",
    "pd.set_option('display.max_columns', None)  # 显示所有列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "depolarizing_csv_path = \"depolarizing.csv\"\n",
    "df = pd.read_csv(depolarizing_csv_path)\n",
    "df = df[df[\"ARG\"] < 0.15]\n",
    "cols_to_avg = [col for col in df.columns[6:] if col != 'p_gate1']\n",
    "df[cols_to_avg] = df[cols_to_avg].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_hard = pd.read_csv('amp_damping_probability.csv')\n",
    "df_hard = df_hard.drop(columns=['pbid'])\n",
    "grouped_df = df_hard.groupby(['amp'], as_index=False).agg({\n",
    "    'ARG': ['mean', 'std'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87176b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "scale = 1\n",
    "mpl.rcParams.update({\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "    'font.family': 'Times New Roman',\n",
    "    'font.size': 60 * scale,\n",
    "    'axes.unicode_minus': False,\n",
    "    'mathtext.fontset': 'custom',\n",
    "    'mathtext.rm': 'Times New Roman',\n",
    "    'mathtext.it': 'Times New Roman:italic',\n",
    "    'mathtext.bf': 'Times New Roman:bold',\n",
    "    'axes.linewidth': 5 * scale,\n",
    "    'xtick.major.size': 20 * scale,\n",
    "    'xtick.major.width': 5 * scale,\n",
    "    'xtick.minor.size': 10 * scale,\n",
    "    'xtick.minor.width': 3 * scale,\n",
    "    'ytick.major.size': 20 * scale,\n",
    "    'ytick.major.width': 5 * scale,\n",
    "    'ytick.minor.size': 10 * scale,\n",
    "    'ytick.minor.width': 3 * scale,\n",
    "    'lines.markersize': 35 * scale,\n",
    "    'lines.markeredgewidth': 4 * scale,\n",
    "    'markers.fillstyle': 'full',\n",
    "    'lines.markerfacecolor': '#f8d941',\n",
    "    'lines.markeredgecolor': 'black',\n",
    "    'hatch.linewidth': 0.2 * scale,\n",
    "    'hatch.color': 'black',\n",
    "    'lines.linewidth': 0.7 * scale,\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(22 * scale, 12 * scale))\n",
    "ax1 = plt.axes((0, 0, 0.415, 0.5))\n",
    "ax2 = plt.axes((0.55, 0, 0.4, 0.5))\n",
    "\n",
    "bar_width = 0.15\n",
    "colors = ['#FFF5E4','#B8001F', '#6A9C89','#384B70']\n",
    "x = np.linspace(0, 1, 1000)\n",
    "for i, category in enumerate([1e-4, 3e-4, 5e-4, 1e-3]):\n",
    "    subset = df[df[\"p_gate1\"] == category][\"ARG\"]\n",
    "    subset = pd.to_numeric(subset, errors='coerce').dropna()\n",
    "    subset = subset[np.isfinite(subset)]\n",
    "    if len(subset) == 0:\n",
    "        continue\n",
    "    mu, sigma = norm.fit(subset)\n",
    "    pdf = norm.pdf(x, mu, sigma)\n",
    "    ax1.plot(x, pdf, color='black', linewidth=3, zorder=1)\n",
    "    ax1.fill_between(x, pdf, color=colors[i], label=f'{category:.0e} (μ={mu:.3f}, σ={sigma:.3f})', zorder=0)\n",
    "\n",
    "\n",
    "ax1.legend(loc='upper right', ncol=1, frameon=False, prop={'size': 33})\n",
    "ax1.set_xlabel('ARG')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_xlim(0, 0.15)\n",
    "ax1.set_ylim(0, 38)\n",
    "\n",
    "bar_width = 0.5\n",
    "colors = ['#FFF5E4', '#B8001F', '#6A9C89', '#384B70']\n",
    "target_amps = [0.0, 0.005, 0.01, 0.015, 0.02]\n",
    "x = np.arange(len(target_amps))\n",
    "\n",
    "for i, amp in enumerate(target_amps):\n",
    "    # 找 grouped_df 里是否有对应的 amp 行\n",
    "    row = grouped_df[grouped_df['amp'] == amp]\n",
    "    if not row.empty:\n",
    "        y_val = row[('ARG', 'mean')].values[0]\n",
    "        color = colors[0]\n",
    "        ax2.bar(\n",
    "            x[i], y_val, bar_width,\n",
    "            color=color, edgecolor=\"black\", linewidth=4 * scale, label=f'{amp:.3f}'\n",
    "        )\n",
    "    else:\n",
    "        ax2.bar(\n",
    "            x[i], 2, bar_width,\n",
    "            color='white', edgecolor=\"black\", linewidth=4 * scale, hatch='/',\n",
    "            label=f'{amp:.3f} (missing)'\n",
    "        )\n",
    "\n",
    "ax2.set_xlabel('amplitude damping probability (%)', fontsize=45)\n",
    "ax2.set_ylabel('ARG')\n",
    "ax2.set_xticks(x, labels=[x_label * 100 for x_label in target_amps])\n",
    "ax2.set_ylim(0, 1.5)\n",
    "ax2.grid(True, linestyle='--', linewidth=1.5 * scale, axis='y')\n",
    "\n",
    "\n",
    "title = \"Figure 14: Evaluation on different noise models\"\n",
    "plt.suptitle(title, y=-0.18, fontsize=48)\n",
    "plt.savefig(f'{title}.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasengan_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
