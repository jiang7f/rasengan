{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend device: GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import signal\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, TimeoutError\n",
    "\n",
    "from rasengan.problems.facility_location_problem import generate_flp\n",
    "from rasengan.problems.k_partition_problem import generate_kpp\n",
    "from rasengan.problems.job_scheduling_problem import generate_jsp\n",
    "from rasengan.problems.set_cover_problem import generate_scp\n",
    "from rasengan.problems.graph_coloring_problem import generate_gcp\n",
    "from rasengan.solvers.optimizers import CobylaOptimizer\n",
    "from rasengan.solvers.qiskit import (\n",
    "    HeaSolver, PenaltySolver, ChocoSolver, RasenganSolver,\n",
    "    AerGpuProvider, AerProvider, DdsimProvider,\n",
    ")\n",
    "from rasengan.utils.qiskit_plugin import detect_device\n",
    "\n",
    "np.random.seed(0x7f)\n",
    "random.seed(0x7f)\n",
    "\n",
    "device = detect_device()\n",
    "print(f\"Backend device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e454428",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = 8\n",
    "problem_scale = 4\n",
    "\n",
    "flp_problems_pkg, flp_configs_pkg = generate_flp(num_cases, [(1, 2), (2, 3), (3, 3), (3, 4)][:problem_scale], 10, 30)\n",
    "kpp_problems_pkg, kpp_configs_pkg = generate_kpp(num_cases, [(4, 2, 3), (5, 3, 4), (6, 3, 5), (7, 3, 6)][:problem_scale], 1, 20)\n",
    "jsp_problems_pkg, jsp_configs_pkg = generate_jsp(num_cases, [(2, 2, 3), (2, 3, 4), (3, 3, 5), (3, 4, 6)][:problem_scale], 1, 20)\n",
    "scp_problems_pkg, scp_configs_pkg = generate_scp(num_cases, [(4, 4), (5, 5), (6, 6), (7, 7)][:problem_scale])\n",
    "gcp_problems_pkg, gcp_configs_pkg = generate_gcp(num_cases, [(3, 1), (3, 2), (4, 1), (4, 2)][:problem_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ARG:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "problem_0 using HeaSolver: 100%|██████████| 8/8 [00:39<00:00,  4.89s/it]\n",
      "problem_0 using PenaltySolver: 100%|██████████| 8/8 [00:21<00:00,  2.70s/it]\n",
      "problem_0 using ChocoSolver: 100%|██████████| 8/8 [00:02<00:00,  3.57it/s]\n",
      "problem_0 using RasenganSolver: 100%|██████████| 8/8 [00:01<00:00,  6.45it/s]\n",
      "problem_1 using HeaSolver: 100%|██████████| 8/8 [05:36<00:00, 42.12s/it] \n",
      "problem_1 using PenaltySolver: 100%|██████████| 8/8 [03:25<00:00, 25.68s/it] \n",
      "problem_1 using ChocoSolver: 100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n",
      "problem_1 using RasenganSolver: 100%|██████████| 8/8 [00:14<00:00,  1.85s/it]\n",
      "problem_2 using HeaSolver: 100%|██████████| 8/8 [17:41<00:00, 132.67s/it]  \n",
      "problem_2 using PenaltySolver: 100%|██████████| 8/8 [09:07<00:00, 68.45s/it] \n",
      "problem_2 using ChocoSolver: 100%|██████████| 8/8 [00:18<00:00,  2.29s/it]\n",
      "problem_2 using RasenganSolver: 100%|██████████| 8/8 [00:33<00:00,  4.25s/it]\n",
      "problem_3 using HeaSolver: 100%|██████████| 8/8 [1:03:37<00:00, 477.20s/it]\n",
      "problem_3 using PenaltySolver: 100%|██████████| 8/8 [51:31<00:00, 386.38s/it]  \n",
      "problem_3 using ChocoSolver: 100%|██████████| 8/8 [01:25<00:00, 10.69s/it]\n",
      "problem_3 using RasenganSolver: 100%|██████████| 8/8 [03:20<00:00, 25.12s/it] \n",
      "problem_4 using HeaSolver: 100%|██████████| 8/8 [01:21<00:00, 10.15s/it]\n",
      "problem_4 using PenaltySolver: 100%|██████████| 8/8 [01:06<00:00,  8.26s/it]\n",
      "problem_4 using ChocoSolver: 100%|██████████| 8/8 [00:03<00:00,  2.15it/s]\n",
      "problem_4 using RasenganSolver: 100%|██████████| 8/8 [00:03<00:00,  2.65it/s]\n",
      "problem_5 using HeaSolver: 100%|██████████| 8/8 [13:51<00:00, 103.94s/it]  \n",
      "problem_5 using PenaltySolver: 100%|██████████| 8/8 [08:22<00:00, 62.86s/it] \n",
      "problem_5 using ChocoSolver: 100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n",
      "problem_5 using RasenganSolver: 100%|██████████| 8/8 [00:07<00:00,  1.11it/s]\n",
      "problem_6 using HeaSolver: 100%|██████████| 8/8 [35:03<00:00, 262.91s/it]   \n",
      "problem_6 using PenaltySolver: 100%|██████████| 8/8 [19:52<00:00, 149.05s/it]\n",
      "problem_6 using ChocoSolver: 100%|██████████| 8/8 [00:46<00:00,  5.76s/it]\n",
      "problem_6 using RasenganSolver: 100%|██████████| 8/8 [02:51<00:00, 21.49s/it]\n",
      "problem_7 using HeaSolver:  12%|█▎        | 1/8 [38:45<4:31:21, 2325.98s/it]"
     ]
    }
   ],
   "source": [
    "evaluate_csv_path = 'evaluate.csv'\n",
    "\n",
    "problems_pkg = list(\n",
    "    itertools.chain(\n",
    "        enumerate(flp_problems_pkg),\n",
    "        enumerate(kpp_problems_pkg),\n",
    "        enumerate(jsp_problems_pkg),\n",
    "        enumerate(scp_problems_pkg),\n",
    "        enumerate(gcp_problems_pkg),\n",
    "    )\n",
    ")\n",
    "\n",
    "solvers = [HeaSolver, PenaltySolver, ChocoSolver, RasenganSolver]\n",
    "evaluation_metrics = ['best_solution_probs', 'in_constraints_probs', 'ARG', 'iteration_count', 'classcial', 'quantum', 'run_times']\n",
    "headers = ['pkid', 'pbid', 'layers', \"variables\", 'constraints', 'method'] + evaluation_metrics\n",
    "\n",
    "def process_layer(prb, num_layers, solver):\n",
    "    opt = CobylaOptimizer(max_iter=200)\n",
    "    ddsim = DdsimProvider(transpile_mode=0)\n",
    "    cpu = AerProvider()\n",
    "    gpu = AerGpuProvider()\n",
    "    baseline_provider = cpu if device == 'CPU' else gpu\n",
    "\n",
    "    prb.set_penalty_lambda(400)\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        provider = baseline_provider if solver in [HeaSolver, PenaltySolver] else ddsim,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "    )\n",
    "    used_solver.solve()\n",
    "    eval = used_solver.evaluation()\n",
    "    time = list(used_solver.time_analyze())\n",
    "    run_times = used_solver.run_counts()\n",
    "    return eval + time + [run_times]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Evaluating ARG:\")\n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 24 * 3 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    # print(evaluate_csv_path)\n",
    "    with open(f'{evaluate_csv_path}', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count()\n",
    "    # pkid-pbid: 问题包序-包内序号\n",
    "    \n",
    "    for pkid, (diff_level, problems) in enumerate(problems_pkg):\n",
    "        for solver in solvers:\n",
    "            # 防止GPU内存溢出\n",
    "            if device == 'GPU' and solver in [HeaSolver, PenaltySolver]:\n",
    "                num_processes = 2**(4 - diff_level)\n",
    "            else:\n",
    "                num_processes = num_processes_cpu // 4\n",
    "\n",
    "            solver_name = solver.__name__\n",
    "            with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                futures = []\n",
    "                layer = 5\n",
    "\n",
    "                for pbid, prb in enumerate(problems):\n",
    "                    # print(f'{pkid}-{pbid}, {layer}, {solver} build')\n",
    "                    future = executor.submit(process_layer, prb, layer, solver)\n",
    "                    futures.append((future, prb, pkid, pbid, layer, solver_name))\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "                for future, prb, pkid, pbid, layer, solver in tqdm(futures, desc=f\"problem_{pkid} using {solver_name}\"):\n",
    "                    current_time = time.perf_counter()\n",
    "                    remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "                    diff = []\n",
    "                    try:\n",
    "                        metrics = future.result(timeout=remaining_time)\n",
    "                        diff.extend(metrics)\n",
    "                        # print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} executed successfully.\")\n",
    "                    except MemoryError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} encountered a MemoryError.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('memory_error')\n",
    "                    except TimeoutError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} timed out.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('timeout')\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "                    finally:\n",
    "                        row = [pkid, pbid, layer, len(prb.variables), len(prb.lin_constr_mtx), solver] + diff\n",
    "                        with open(f'{evaluate_csv_path}', mode='a', newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow(row)  # Write row immediately\n",
    "                        num_complete += 1\n",
    "                        if num_complete == len(futures):\n",
    "                            # print(f'problem_pkg_{pkid} has finished')\n",
    "                            for process in executor._processes.values():\n",
    "                                os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {evaluate_csv_path}')\n",
    "    print(f\"Time elapsed: {time.perf_counter() - all_start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294bc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_and_num_params_csv_path = 'depth_and_num_params.csv'\n",
    "problems_pkg = flp_problems_pkg + kpp_problems_pkg + jsp_problems_pkg + scp_problems_pkg + gcp_problems_pkg\n",
    "metrics_lst = ['depth', 'num_params']\n",
    "solvers = [HeaSolver, PenaltySolver, ChocoSolver, RasenganSolver]\n",
    "headers = [\"pkid\", 'method', 'layers'] + metrics_lst\n",
    "\n",
    "def process_layer(prb, num_layers, solver, metrics_lst):\n",
    "    opt = CobylaOptimizer(max_iter=300)\n",
    "    ddsim = DdsimProvider()\n",
    "    cpu = AerProvider()\n",
    "    gpu = AerGpuProvider()\n",
    "    baseline_provider = cpu if device == 'CPU' else gpu\n",
    "\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        provider = baseline_provider if solver in [HeaSolver, PenaltySolver] else ddsim,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "    )\n",
    "    metrics = used_solver.circuit_analyze(metrics_lst)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 24 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    with open(f'{depth_and_num_params_csv_path}', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count() // 2\n",
    "    with ProcessPoolExecutor(max_workers=num_processes_cpu) as executor:\n",
    "        futures = []\n",
    "        for solver in solvers:\n",
    "            for pkid, problems in enumerate(problems_pkg):\n",
    "                for problem in problems:\n",
    "                    num_layers = 5\n",
    "                    future = executor.submit(process_layer, problem, num_layers, solver, metrics_lst)\n",
    "                    futures.append((future, pkid, solver.__name__, num_layers))\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        for future, pkid, solver, num_layers in tqdm(futures, desc=\"Evaluating depth and num_params\"):\n",
    "            current_time = time.perf_counter()\n",
    "            remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "            diff = []\n",
    "            try:\n",
    "                result = future.result(timeout=remaining_time)\n",
    "                diff.extend(result)\n",
    "                # print(f\"Task for problem {pkid}, num_layers {num_layers} executed successfully.\")\n",
    "            except MemoryError:\n",
    "                diff.append('memory_error')\n",
    "                print(f\"Task for problem {pkid}, num_layers {num_layers} encountered a MemoryError.\")\n",
    "            except TimeoutError:\n",
    "                diff.append('timeout')\n",
    "                print(f\"Task for problem {pkid}, num_layers {num_layers} timed out.\")\n",
    "            finally:\n",
    "                row = [pkid, solver, num_layers] + diff\n",
    "                with open(f'{depth_and_num_params_csv_path}', mode='a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(row)  # Write row immediately\n",
    "                num_complete += 1\n",
    "                if num_complete == len(futures):\n",
    "                    # print(f'Data has been written to {depth_and_num_params_csv_path}')\n",
    "                    for process in executor._processes.values():\n",
    "                        os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {depth_and_num_params_csv_path}')\n",
    "    print(f\"Time elapsed: {time.perf_counter() - all_start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f65e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "depth_and_num_params_csv_path = 'depth_and_num_params.csv'\n",
    "evaluate_csv_path = 'evaluate.csv'\n",
    "problem_scale = 4\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 输入路径\n",
    "depth_and_num_params_csv_path = 'depth_and_num_params.csv'\n",
    "evaluate_csv_path = 'evaluate.csv'\n",
    "problem_scale = 4\n",
    "\n",
    "# 读入 Depth 和 Params 数据\n",
    "df = pd.read_csv(depth_and_num_params_csv_path)\n",
    "df.loc[df[\"method\"] == \"HeaSolver\", \"method\"] = \"HEA\"\n",
    "df.loc[df[\"method\"] == \"PenaltySolver\", \"method\"] = \"P-QAOA\"\n",
    "df.loc[df[\"method\"] == \"ChocoSolver\", \"method\"] = \"Choco-Q\"\n",
    "df.loc[df[\"method\"] == \"RasenganSolver\", \"method\"] = \"Rasengan\"\n",
    "\n",
    "benchmarks = [\"F\", \"K\", \"J\", \"S\", \"G\"]\n",
    "method_order = ['HEA', 'P-QAOA', 'Choco-Q', 'Rasengan']\n",
    "\n",
    "# pkid → Benchmark label，如 F1, F2, ..., G4\n",
    "pkid_to_label = {\n",
    "    pkid: f\"{b}{i}\"\n",
    "    for pkid, (b, i) in enumerate(\n",
    "        ((b, i) for b in benchmarks for i in range(1, problem_scale + 1))\n",
    "    )\n",
    "}\n",
    "df[\"Benchmark\"] = df[\"pkid\"].map(pkid_to_label)\n",
    "df[\"method\"] = pd.Categorical(df[\"method\"], categories=method_order, ordered=True)\n",
    "\n",
    "# 聚合\n",
    "df_grouped = df.groupby([\"method\", \"Benchmark\"], observed=True).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# 构建 pivot 表格\n",
    "pivot_depth = df_grouped.pivot(index=\"method\", columns=\"Benchmark\", values=\"depth\")\n",
    "pivot_param = df_grouped.pivot(index=\"method\", columns=\"Benchmark\", values=\"num_params\")\n",
    "pivot_depth.loc[\"Rasengan\"] = pivot_depth.loc[\"Rasengan\"] / pivot_param.loc[\"Rasengan\"]\n",
    "\n",
    "# ARG 数据处理\n",
    "df_eval = pd.read_csv(evaluate_csv_path)\n",
    "df_eval.loc[df_eval[\"method\"] == \"HeaSolver\", \"method\"] = \"HEA\"\n",
    "df_eval.loc[df_eval[\"method\"] == \"PenaltySolver\", \"method\"] = \"P-QAOA\"\n",
    "df_eval.loc[df_eval[\"method\"] == \"ChocoSolver\", \"method\"] = \"Choco-Q\"\n",
    "df_eval.loc[df_eval[\"method\"] == \"RasenganSolver\", \"method\"] = \"Rasengan\"\n",
    "df_eval = df_eval[df_eval['ARG'] <= 100000]\n",
    "df_eval[\"Benchmark\"] = df_eval[\"pkid\"].map(pkid_to_label)\n",
    "df_eval[\"method\"] = pd.Categorical(df_eval[\"method\"], categories=method_order, ordered=True)\n",
    "df_arg_grouped = df_eval.groupby([\"method\", \"Benchmark\"], observed=True)[\"ARG\"].mean().reset_index()\n",
    "pivot_arg = df_arg_grouped.pivot(index=\"method\", columns=\"Benchmark\", values=\"ARG\")\n",
    "\n",
    "# 列顺序对齐\n",
    "column_order = list(pkid_to_label.values())\n",
    "pivot_depth = pivot_depth[column_order]\n",
    "pivot_param = pivot_param[column_order]\n",
    "pivot_arg = pivot_arg[column_order]\n",
    "\n",
    "# 四舍五入\n",
    "\n",
    "# 多级索引\n",
    "depth_labeled = pivot_depth.copy()\n",
    "depth_labeled.index = pd.MultiIndex.from_product([[\"Depth\"], depth_labeled.index])\n",
    "param_labeled = pivot_param.copy()\n",
    "param_labeled.index = pd.MultiIndex.from_product([[\"#Params\"], param_labeled.index])\n",
    "arg_labeled = pivot_arg.copy()\n",
    "arg_labeled.index = pd.MultiIndex.from_product([[\"ARG\"], arg_labeled.index])\n",
    "\n",
    "# === 计算 improvement ===\n",
    "def compute_improvement(target_df, baseline=\"Rasengan\"):\n",
    "    improvements = {}\n",
    "    for method in method_order:\n",
    "        if method == baseline:\n",
    "            improvements[method] = None\n",
    "            continue\n",
    "        ratio = target_df.loc[method] / target_df.loc[baseline]\n",
    "        improvements[method] = ratio.mean()\n",
    "    return improvements\n",
    "\n",
    "def append_improvement_column(df, improvements):\n",
    "    df = df.copy()\n",
    "    df[\"improvement\"] = [\n",
    "        round(val, 3) if val is not None else pd.NA\n",
    "        for val in [improvements.get(method, pd.NA) for method in df.index.get_level_values(1)]\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "# 分别计算 improvement 并添加列\n",
    "arg_improvements = compute_improvement(pivot_arg)\n",
    "depth_improvements = compute_improvement(pivot_depth)\n",
    "param_improvements = compute_improvement(pivot_param)\n",
    "\n",
    "depth_labeled = depth_labeled.round().astype(\"Int64\").astype(str)\n",
    "param_labeled = param_labeled.round().astype(\"Int64\").astype(str)\n",
    "arg_labeled = arg_labeled.round(3)\n",
    "\n",
    "arg_labeled = append_improvement_column(arg_labeled, arg_improvements)\n",
    "depth_labeled = append_improvement_column(depth_labeled, depth_improvements)\n",
    "param_labeled = append_improvement_column(param_labeled, param_improvements)\n",
    "\n",
    "# 合并最终表格\n",
    "merged_with_improvement = pd.concat([arg_labeled, depth_labeled, param_labeled])\n",
    "merged_with_improvement.to_pickle(\"table_2.pkl\")\n",
    "\n",
    "# 显示结果\n",
    "merged_with_improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasengan_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
