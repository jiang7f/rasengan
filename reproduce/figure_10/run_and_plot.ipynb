{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7255fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import signal\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, TimeoutError\n",
    "from rasengan.problems.facility_location_problem import generate_flp\n",
    "from rasengan.solvers.optimizers import CobylaOptimizer\n",
    "from rasengan.solvers.qiskit import (\n",
    "    ChocoSolver, QtoSolver, RasenganSolver, RasenganSegmentedSolver, \n",
    "    FakeQuebecProvider, DdsimProvider, NoisyDdsimProvider\n",
    ")\n",
    "\n",
    "np.random.seed(0xdb)\n",
    "random.seed(0x7f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92eca01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating #segments and depth: 100%|██████████| 22/22 [08:34<00:00, 23.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to segments_and_depth.csv\n"
     ]
    }
   ],
   "source": [
    "m, n = 7, 7\n",
    "num_case = 1\n",
    "csv_path = \"segments_and_depth.csv\"\n",
    "num_processes_cpu = os.cpu_count()\n",
    "num_processes = max(1, num_processes_cpu // 4)\n",
    "\n",
    "scale_list = [(i, j) for i in range(1, m + 1) for j in range(2, n + 1)][:22]\n",
    "a, b = generate_flp(num_case, scale_list, 1, 20)\n",
    "metrics_lst = ['depth', 'num_params']\n",
    "\n",
    "with open(f'{csv_path}', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"m\", \"n\", \"variables\"] + metrics_lst + ['depth_2', 'num_params_2'])\n",
    "\n",
    "def process_layer(i):\n",
    "    scale = scale_list[i]\n",
    "    prb_model = a[i][0]\n",
    "    num_vars = b[i][0][1]\n",
    "\n",
    "    prb_model.set_penalty_lambda(200)\n",
    "\n",
    "    opt = CobylaOptimizer(max_iter=50)\n",
    "    provider = FakeQuebecProvider(transpile_mode=1)\n",
    "\n",
    "    solver_1 = RasenganSolver(\n",
    "        prb_model=prb_model,\n",
    "        optimizer=opt,\n",
    "        provider=provider,\n",
    "        num_layers=5,\n",
    "        shots=1024,\n",
    "        opt_mode=[0, 0]\n",
    "    )\n",
    "    solver_2 = QtoSolver(\n",
    "        prb_model=prb_model,\n",
    "        optimizer=opt,\n",
    "        provider=provider,\n",
    "        num_layers=5,\n",
    "        shots=1024,\n",
    "    )\n",
    "\n",
    "    metrics_1 = solver_1.circuit_analyze(metrics_lst)\n",
    "    metrics_2 = solver_2.circuit_analyze(metrics_lst)\n",
    "\n",
    "    return [scale[0], scale[1], num_vars] + metrics_1 + metrics_2\n",
    "\n",
    "futures = []\n",
    "with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "    for i in range(len(scale_list)):\n",
    "        futures.append(executor.submit(process_layer, i))\n",
    "\n",
    "    for future in tqdm(futures, desc=\"Evaluating #segments and depth\"):\n",
    "        result = future.result()\n",
    "        with open(f'{csv_path}', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(result)\n",
    "\n",
    "print(f'Data has been written to {csv_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ARG on large-scale problems:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "problem_0 using ChocoSolver: 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]\n",
      "problem_0 using RasenganSolver: 100%|██████████| 10/10 [00:01<00:00,  7.81it/s]\n",
      "problem_1 using ChocoSolver: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]\n",
      "problem_1 using RasenganSolver: 100%|██████████| 10/10 [00:03<00:00,  2.81it/s]\n",
      "problem_2 using ChocoSolver: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
      "problem_2 using RasenganSolver: 100%|██████████| 10/10 [00:20<00:00,  2.10s/it]\n",
      "problem_3 using ChocoSolver: 100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "problem_3 using RasenganSolver: 100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n",
      "problem_4 using ChocoSolver: 100%|██████████| 10/10 [00:31<00:00,  3.17s/it]\n",
      "problem_4 using RasenganSolver: 100%|██████████| 10/10 [01:17<00:00,  7.76s/it]\n",
      "problem_5 using ChocoSolver:  10%|█         | 1/10 [01:41<15:11, 101.33s/it]"
     ]
    }
   ],
   "source": [
    "num_cases = 10\n",
    "\n",
    "flp_problems_pkg, flp_configs_pkg = generate_flp(num_cases, [(1, 2), (2, 2), (2, 3), (3, 2), (3, 3), (3, 4), (4, 3)], 1, 100)\n",
    "\n",
    "large_evaluation_csv_path = \"large_evaluation.csv\"\n",
    "problems_pkg = list(\n",
    "    itertools.chain(\n",
    "        enumerate(flp_problems_pkg),\n",
    "    )\n",
    ")\n",
    "solvers = [ChocoSolver, RasenganSolver]\n",
    "evaluation_metrics = ['best_solution_probs', 'in_constraints_probs', 'ARG', 'iteration_count', 'classcial', 'quantum', 'run_times']\n",
    "headers = ['pkid', 'pbid', 'layers', \"variables\", 'constraints', 'method'] + evaluation_metrics\n",
    "\n",
    "\n",
    "def process_layer(prb, num_layers, solver):\n",
    "    opt = CobylaOptimizer(max_iter=500)\n",
    "    aer = DdsimProvider()\n",
    "    prb.set_penalty_lambda(400)\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        provider = aer,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "    )\n",
    "    used_solver.solve()\n",
    "    eval = used_solver.evaluation()\n",
    "    time = list(used_solver.time_analyze())\n",
    "    run_times = used_solver.run_counts()\n",
    "    return eval + time + [run_times]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Evaluating ARG on large-scale problems:\")\n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 24 * 3 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    # print(evaluate_csv_path)\n",
    "    with open(f'{large_evaluation_csv_path}', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count()\n",
    "    num_processes = num_processes_cpu // 4\n",
    "    # pkid-pbid: 问题包序-包内序号\n",
    "    \n",
    "    for pkid, (diff_level, problems) in enumerate(problems_pkg):\n",
    "        for solver in solvers:\n",
    "\n",
    "            solver_name = solver.__name__\n",
    "            with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                futures = []\n",
    "                layer = 5\n",
    "\n",
    "                for pbid, prb in enumerate(problems):\n",
    "                    future = executor.submit(process_layer, prb, layer, solver)\n",
    "                    futures.append((future, prb, pkid, pbid, layer, solver_name))\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "                for future, prb, pkid, pbid, layer, solver in tqdm(futures, desc=f\"problem_{pkid} using {solver_name}\"):\n",
    "                    current_time = time.perf_counter()\n",
    "                    remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "                    diff = []\n",
    "                    try:\n",
    "                        metrics = future.result(timeout=remaining_time)\n",
    "                        diff.extend(metrics)\n",
    "                        # print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} executed successfully.\")\n",
    "                    except MemoryError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} encountered a MemoryError.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('memory_error')\n",
    "                    except TimeoutError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} timed out.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('timeout')\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "                    finally:\n",
    "                        row = [pkid, pbid, layer, len(prb.variables), len(prb.lin_constr_mtx), solver] + diff\n",
    "                        with open(f'{large_evaluation_csv_path}', mode='a', newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow(row)  # Write row immediately\n",
    "                        num_complete += 1\n",
    "                        if num_complete == len(futures):\n",
    "                            # print(f'problem_pkg_{pkid} has finished')\n",
    "                            for process in executor._processes.values():\n",
    "                                os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {large_evaluation_csv_path}')\n",
    "    print(f\"Time elapsed: {time.perf_counter() - all_start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = 5\n",
    "\n",
    "flp_problems_pkg, flp_configs_pkg = generate_flp(num_cases, [(1, 2), (2, 2), (2, 3), (3, 2), (3, 3), (3, 4), (4, 3)], 1, 100)\n",
    "\n",
    "noisy_evaluation_csv_path = \"noisy_evaluation.csv\"\n",
    "problems_pkg = list(\n",
    "    itertools.chain(\n",
    "        enumerate(flp_problems_pkg),\n",
    "    )\n",
    ")\n",
    "solvers = [RasenganSegmentedSolver]\n",
    "evaluation_metrics = ['best_solution_probs', 'in_constraints_probs', 'ARG', 'iteration_count', 'classcial', 'quantum', 'run_times']\n",
    "headers = ['pkid', 'pbid', 'layers', \"variables\", 'constraints', 'method'] + evaluation_metrics\n",
    "\n",
    "\n",
    "def process_layer(prb, num_layers, solver):\n",
    "    opt = CobylaOptimizer(max_iter=500)\n",
    "    aer = NoisyDdsimProvider()\n",
    "    prb.set_penalty_lambda(400)\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        provider = aer,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "        num_segments = 10,\n",
    "    )\n",
    "    used_solver.solve()\n",
    "    eval = used_solver.evaluation()\n",
    "    time = list(used_solver.time_analyze())\n",
    "    run_times = used_solver.run_counts()\n",
    "    return eval + time + [run_times]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Evaluating ARG under noise:\")\n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 24 * 3 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    # print(evaluate_csv_path)\n",
    "    with open(f'{noisy_evaluation_csv_path}', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count()\n",
    "    num_processes = num_processes_cpu // 4\n",
    "    # pkid-pbid: 问题包序-包内序号\n",
    "    \n",
    "    for pkid, (diff_level, problems) in enumerate(problems_pkg):\n",
    "        for solver in solvers:\n",
    "\n",
    "            solver_name = solver.__name__\n",
    "            with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                futures = []\n",
    "                layer = 5\n",
    "\n",
    "                for pbid, prb in enumerate(problems):\n",
    "                    future = executor.submit(process_layer, prb, layer, solver)\n",
    "                    futures.append((future, prb, pkid, pbid, layer, solver_name))\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "                for future, prb, pkid, pbid, layer, solver in tqdm(futures, desc=f\"problem_{pkid} using {solver_name}\"):\n",
    "                    current_time = time.perf_counter()\n",
    "                    remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "                    diff = []\n",
    "                    try:\n",
    "                        metrics = future.result(timeout=remaining_time)\n",
    "                        diff.extend(metrics)\n",
    "                        # print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} executed successfully.\")\n",
    "                    except MemoryError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} encountered a MemoryError.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('memory_error')\n",
    "                    except TimeoutError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} timed out.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('timeout')\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "                    finally:\n",
    "                        row = [pkid, pbid, layer, len(prb.variables), len(prb.lin_constr_mtx), solver] + diff\n",
    "                        with open(f'{noisy_evaluation_csv_path}', mode='a', newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow(row)  # Write row immediately\n",
    "                        num_complete += 1\n",
    "                        if num_complete == len(futures):\n",
    "                            # print(f'problem_pkg_{pkid} has finished')\n",
    "                            for process in executor._processes.values():\n",
    "                                os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {noisy_evaluation_csv_path}')\n",
    "    print(f\"Time elapsed: {time.perf_counter() - all_start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca807242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('segments_and_depth.csv')\n",
    "df_sorted = df.sort_values(by='variables')\n",
    "\n",
    "def preprocess_df(filepath, methods):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop(columns=['pbid'])\n",
    "    df = df[df['ARG'] <= 100000]\n",
    "    grouped = df.groupby(['variables', 'method'], as_index=False).agg({\n",
    "        'iteration_count': 'mean',\n",
    "        'classcial': 'mean',\n",
    "        'run_times': 'mean',\n",
    "        'ARG': 'mean',\n",
    "        'in_constraints_probs': 'mean',\n",
    "        'best_solution_probs': 'mean',\n",
    "    })\n",
    "    values = [\"variables\", \"ARG\", 'best_solution_probs', 'classcial', 'in_constraints_probs', 'run_times', 'iteration_count']\n",
    "    pivot = grouped.pivot(index='variables', columns='method', values=values)\n",
    "    pivot = pivot.reindex(columns=pd.MultiIndex.from_product([values, methods]))\n",
    "    return pivot\n",
    "\n",
    "pivot_df_1 = preprocess_df('large_evaluation.csv', methods=['ChocoSolver', 'RasenganSolver'])\n",
    "pivot_df_2 = preprocess_df('noisy_evaluation.csv', methods=['RasenganSegmentedSolver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ceca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "    'font.family': 'Times New Roman',\n",
    "    'font.size': 60,\n",
    "    'axes.unicode_minus': False,\n",
    "    'mathtext.fontset': 'custom',\n",
    "    'mathtext.rm': 'Times New Roman',\n",
    "    'mathtext.it': 'Times New Roman:italic',\n",
    "    'mathtext.bf': 'Times New Roman:bold',\n",
    "    'axes.linewidth': 5,\n",
    "    'xtick.major.size': 20,\n",
    "    'xtick.major.width': 5,\n",
    "    'xtick.minor.size': 10,\n",
    "    'xtick.minor.width': 3,\n",
    "    'ytick.major.size': 20,\n",
    "    'ytick.major.width': 5,\n",
    "    'ytick.minor.size': 10,\n",
    "    'ytick.minor.width': 3,\n",
    "    \"lines.markersize\": 35,\n",
    "    \"lines.markeredgewidth\": 4,\n",
    "    \"markers.fillstyle\": 'full',\n",
    "    'lines.markerfacecolor': '#f8d941',\n",
    "    'lines.markeredgecolor': 'black',\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(22, 12))\n",
    "\n",
    "ax1 = plt.axes([0, 0.7, 0.4, 0.5])\n",
    "ax2 = plt.axes([0.5, 0.7, 0.5, 0.5])\n",
    "ax3 = plt.axes([0, 0, 0.55, 0.5])\n",
    "ax4 = plt.axes([0.67, 0, 0.35, 0.5])\n",
    "\n",
    "ax1.plot(df_sorted['variables'], df_sorted['num_params'], marker='o', linestyle='-', \n",
    "         color='#384B70', linewidth=4, markersize=15, markeredgewidth=0, markerfacecolor='#384B70')\n",
    "ax1.plot(df_sorted['variables'], df_sorted['num_params_2'], marker='o', linestyle='-', \n",
    "         color='#B8001F', linewidth=4, markersize=15, markeredgewidth=0, markerfacecolor='#B8001F')\n",
    "\n",
    "ax1.set_xlabel('#variables')\n",
    "ax1.set_ylabel('#segments')\n",
    "ax1.grid(True, linestyle='--', linewidth=1.5, axis='y')\n",
    "ax1.set_yscale('function', functions=(lambda x: np.sqrt(x), lambda x: x**2))\n",
    "ax1.set_yticks(np.arange(0, 2600, 500))\n",
    "ax1.set_yticks(np.arange(0, 2600, 100), minor=True)\n",
    "ax1.set_xticks(np.arange(0, 51, 10))\n",
    "ax1.set_xticks(np.arange(0, 51, 5), minor=True)\n",
    "ax1.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "\n",
    "def plot_fit_line(x, y, color, ax, str):\n",
    "    coef = np.polyfit(x, y, 2)\n",
    "    poly = np.poly1d(coef)\n",
    "    ax.plot(x, poly(x), color=color, linestyle='--', linewidth=3)\n",
    "    a, b, c = coef\n",
    "    eq_str = f\"{str}: $y = {a:.2f}x^2$\"\n",
    "    ax.plot([], [], linestyle='--', color=color, label=eq_str)\n",
    "\n",
    "plot_fit_line(df_sorted['variables'], df_sorted['num_params'], '#384B70', ax1, \"Theorem 1\")\n",
    "plot_fit_line(df_sorted['variables'], df_sorted['num_params_2'], '#B8001F', ax1, \"pruned\")\n",
    "ax1.legend(\n",
    "    loc='upper left', ncol=1, frameon=False,\n",
    "    bbox_to_anchor=(0, 1), mode=\"expand\", borderaxespad=0,\n",
    "    fontsize=35\n",
    ")\n",
    "\n",
    "\n",
    "ratio_1 = df_sorted['depth'] / df_sorted['num_params']\n",
    "ratio_2 = df_sorted['depth_2'] / df_sorted['num_params']\n",
    "\n",
    "ax2.bar(df_sorted['variables'], ratio_1, width=2, color='#6A9C89', edgecolor='black', linewidth=2, label=\"transpiled circuit (quebec)\")\n",
    "ax2.bar(df_sorted['variables'], ratio_2, width=2, color='#afc4bc', hatch='/', edgecolor='black', linewidth=2, label=\"after Hamiltonian pruning\")\n",
    "ax2.legend(\n",
    "    loc='upper left', ncol=1, frameon=False,\n",
    "    bbox_to_anchor=(0, 1), mode=\"expand\", borderaxespad=0,\n",
    "    fontsize=50\n",
    ")\n",
    "\n",
    "ax2.set_xlabel('#variables')\n",
    "ax2.set_ylabel('depth')\n",
    "ax2.grid(True, linestyle='--', linewidth=1.5, axis='y')\n",
    "ax2.set_yticks(np.arange(0, 4000, 1000))\n",
    "ax2.set_yticks(np.arange(0, 4000, 200), minor=True)\n",
    "ax2.set_xticks(np.arange(0, 51, 10))\n",
    "ax2.set_xticks(np.arange(0, 51, 5), minor=True)\n",
    "ax2.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "\n",
    "# \n",
    "\n",
    "colors = ['#B8001F', '#FFF5E4', '#FFF']\n",
    "\n",
    "arg_data = pivot_df_1['ARG']\n",
    "bar_width = 0.35\n",
    "pkid_values = arg_data.index.unique()\n",
    "index = np.arange(len(pkid_values))\n",
    "\n",
    "label_list = [\"Choco-Q\", \"Rasengan\"]\n",
    "for idx, method in enumerate(arg_data.columns):\n",
    "    ax3.bar(index + idx * bar_width, arg_data[method].values, bar_width,\n",
    "            label=label_list[idx], color=colors[idx % len(colors)], edgecolor=\"black\", linewidth=4)\n",
    "\n",
    "ax3.legend(\n",
    "    loc='upper left', ncol=1, frameon=False,\n",
    "    bbox_to_anchor=(0, 1), mode=\"expand\", borderaxespad=0,\n",
    "    fontsize=50\n",
    ")\n",
    "ax3.set_xlabel('#variables', fontsize=60)\n",
    "ax3.set_ylabel('ARG', fontsize=60)\n",
    "ax3.set_xticks(index + bar_width * (len(arg_data.columns) / 2 - 0.5))\n",
    "ax3.set_xticklabels(pkid_values)\n",
    "ax3.grid(True, linestyle='--', linewidth=1.5, axis='y')\n",
    "ax3.set_yticks([i / 10 for i in range(0, 11, 5)])\n",
    "ax3.set_yticks([i / 10 for i in range(0, 11, 1)], minor=True)\n",
    "\n",
    "arg_data_2 = pivot_df_2['ARG']\n",
    "bar_width = 0.4\n",
    "pkid_values_2 = arg_data_2.index.unique()\n",
    "index_2 = np.arange(len(pkid_values_2))\n",
    "\n",
    "for idx, method in enumerate(arg_data_2.columns):\n",
    "    ax4.bar(index_2 + idx * bar_width / 2, arg_data_2[method].values, bar_width,\n",
    "            label=method, color=colors[1], edgecolor=\"black\", linewidth=4)\n",
    "\n",
    "ax4.set_xlabel('#variables', fontsize=60)\n",
    "ax4.set_ylabel('ARG', fontsize=60)\n",
    "ax4.set_xticks(index_2)\n",
    "ax4.set_xticklabels(pkid_values_2)\n",
    "ax4.grid(True, linestyle='--', linewidth=1.5, axis='y')\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.set_yticks([i / 10 for i in range(0, 11, 5)])\n",
    "ax4.set_yticks([i / 10 for i in range(0, 11, 1)], minor=True)\n",
    "\n",
    "title = \"Figure 10: Scalability analysis on large-scale FLP problems\"\n",
    "plt.suptitle(title, y=-0.2, fontsize=48)\n",
    "plt.savefig(f'{title}.svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasengan_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
